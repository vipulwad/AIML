{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHsBFXpc7EDl"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vipul\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1706342898769,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "qsrc2cej7G2W"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Check for device\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1706342898769,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "Pvt_JBVk7LJ4",
    "outputId": "012a2e3a-5ebf-40d1-e3c8-f9fe7d76468b"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Cuda to run on GPU!\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w1PkSKI6-0u"
   },
   "source": [
    "# Initializing Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1706342898770,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "gXXT-W1p6JMx"
   },
   "outputs": [],
   "source": [
    "# Initializing a Tensor in this case of shape 2x3 (2 rows, 3 columns)\n",
    "my_tensor = torch.tensor(\n",
    "    [[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=device, requires_grad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qvqz4DL7Uud"
   },
   "source": [
    "# A few tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1706342898770,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "AlCqmH_p7Wia",
    "outputId": "eab2d957-c6c4-44aa-a0b2-095011ec7eac"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Information about tensor: {my_tensor}\"\n",
    ")  # Prints data of the tensor, device and grad info\n",
    "print(\n",
    "    \"Type of Tensor {my_tensor.dtype}\"\n",
    ")  # Prints dtype of the tensor (torch.float32, etc)\n",
    "print(\n",
    "    f\"Device Tensor is on {my_tensor.device}\"\n",
    ")  # Prints cpu/cuda (followed by gpu number)\n",
    "print(f\"Shape of tensor {my_tensor.shape}\")  # Prints shape, in this case 2x3\n",
    "print(f\"Requires gradient: {my_tensor.requires_grad}\")  # Prints true/false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVUIg0eb7cww"
   },
   "source": [
    "# Other common initialization methods (there exists a ton more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706342898770,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "1XWb5D2c7Z-S"
   },
   "outputs": [],
   "source": [
    "x = torch.empty(size=(3, 3))  # Tensor of shape 3x3 with uninitialized data\n",
    "x = torch.zeros((3, 3))  # Tensor of shape 3x3 with values of 0\n",
    "x = torch.rand(\n",
    "    (3, 3)\n",
    ")  # Tensor of shape 3x3 with values from uniform distribution in interval [0,1)\n",
    "x = torch.ones((3, 3))  # Tensor of shape 3x3 with values of 1\n",
    "x = torch.eye(5, 5)  # Returns Identity Matrix I, (I <-> Eye), matrix of shape 2x3\n",
    "x = torch.arange(\n",
    "    start=0, end=5, step=1\n",
    ")  # Tensor [0, 1, 2, 3, 4], note, can also do: torch.arange(11)\n",
    "x = torch.linspace(start=0.1, end=1, steps=10)  # x = [0.1, 0.2, ..., 1]\n",
    "x = torch.empty(size=(1, 5)).normal_(\n",
    "    mean=0, std=1\n",
    ")  # Normally distributed with mean=0, std=1\n",
    "x = torch.empty(size=(1, 5)).uniform_(\n",
    "    0, 1\n",
    ")  # Values from a uniform distribution low=0, high=1\n",
    "x = torch.diag(torch.ones(3))  # Diagonal matrix of shape 3x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jm--D9g7jz3"
   },
   "source": [
    "# How to make initialized tensors to other types (int, float, double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1706342898770,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "_9W1wN2r7gFq",
    "outputId": "1bbe2dbd-f519-4ef7-c94f-0eca7a0b0c6b"
   },
   "outputs": [],
   "source": [
    "# These will work even if you're on CPU or CUDA!\n",
    "tensor = torch.arange(4)  # [0, 1, 2, 3] Initialized as int64 by default\n",
    "print(f\"Converted Boolean: {tensor.bool()}\")  # Converted to Boolean: 1 if nonzero\n",
    "print(f\"Converted int16 {tensor.short()}\")  # Converted to int16\n",
    "print(\n",
    "    f\"Converted int64 {tensor.long()}\"\n",
    ")  # Converted to int64 (This one is very important, used super often)\n",
    "print(f\"Converted float16 {tensor.half()}\")  # Converted to float16\n",
    "print(\n",
    "    f\"Converted float32 {tensor.float()}\"\n",
    ")  # Converted to float32 (This one is very important, used super often)\n",
    "print(f\"Converted float64 {tensor.double()}\")  # Converted to float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfMNzl387mvO"
   },
   "source": [
    "# Array to Tensor conversion and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1706342899616,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "xz81mgQB7oRC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.zeros((5, 5))\n",
    "tensor = torch.from_numpy(np_array)\n",
    "np_array_again = (\n",
    "    tensor.numpy()\n",
    ")  # np_array_again will be same as np_array (perhaps with numerical round offs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZbrgbXE7sTc"
   },
   "source": [
    "# Tensor Math & Comparison Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "HJ4o9PxM7qKz"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([9, 8, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d27CKgp87wRV"
   },
   "source": [
    "# -- Addition --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "zN0f17aX7wtM"
   },
   "outputs": [],
   "source": [
    "z1 = torch.empty(3)\n",
    "torch.add(x, y, out=z1)  # This is one way\n",
    "z2 = torch.add(x, y)  # This is another way\n",
    "z = x + y  # This is my preferred way, simple and clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmXDfS_Y70Ba"
   },
   "source": [
    "# -- Subtraction --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "nfPObLhN72ys"
   },
   "outputs": [],
   "source": [
    "z = x - y  # We can do similarly as the preferred way of addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyK0pysO732W"
   },
   "source": [
    "# -- Division --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "oa3kDmXv78Nj"
   },
   "outputs": [],
   "source": [
    "z = torch.true_divide(x, y)  # Will do element wise division if of equal shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKthZS9v776G"
   },
   "source": [
    "# -- Inplace Operations --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "1ohBCAl07-yO"
   },
   "outputs": [],
   "source": [
    "t = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "MGz7gw9t8EMi"
   },
   "outputs": [],
   "source": [
    "t.add_(x)  # Whenever we have operation followed by _ it will mutate the tensor in place\n",
    "t += x  # Also inplace: t = t + x is not inplace, bit confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgUl0Qjx8HVu"
   },
   "source": [
    "# -- Exponentiation (Element wise if vector or matrices) --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "EshnjGBO8IvB"
   },
   "outputs": [],
   "source": [
    "z = x.pow(2)  # z = [1, 4, 9]\n",
    "z = x ** 2  # z = [1, 4, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpwpcY8q8Kh5"
   },
   "source": [
    "# -- Simple Comparison --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1706342899617,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "A4ZmVNYn8Lmd"
   },
   "outputs": [],
   "source": [
    "z = x > 0  # Returns [True, True, True]\n",
    "z = x < 0  # Returns [False, False, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTc3qLvh8Omp"
   },
   "source": [
    "# -- Matrix Multiplication --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "3fDPl-nL8QAR"
   },
   "outputs": [],
   "source": [
    "x1 = torch.rand((2, 5))\n",
    "x2 = torch.rand((5, 3))\n",
    "x3 = torch.mm(x1, x2)  # Matrix multiplication of x1 and x2, out shape: 2x3\n",
    "x3 = x1.mm(x2)  # Similar as line above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP3gMVyP8R-0"
   },
   "source": [
    "# -- Matrix Exponentiation --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "BxAFQLuI8UUa",
    "outputId": "063b759a-f7e9-4228-c8d0-4451d84943f1"
   },
   "outputs": [],
   "source": [
    "matrix_exp = torch.rand(5, 5)\n",
    "print(\n",
    "    matrix_exp.matrix_power(3)\n",
    ")  # is same as matrix_exp (mm) matrix_exp (mm) matrix_exp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "068xJwuX8WLn"
   },
   "source": [
    "# -- Element wise Multiplication --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "83AVGp_78XCq"
   },
   "outputs": [],
   "source": [
    "z = x * y  # z = [9, 16, 21] = [1*9, 2*8, 3*7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eD8zqLMH8aVb"
   },
   "source": [
    "# -- Dot product --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "L1mPpWYP8bJ_"
   },
   "outputs": [],
   "source": [
    "z = torch.dot(x, y)  # Dot product, in this case z = 1*9 + 2*8 + 3*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzUnYR1z8dJ1"
   },
   "source": [
    "# -- Batch Matrix Multiplication --\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "POTD2MwU8fS5"
   },
   "outputs": [],
   "source": [
    "batch = 32\n",
    "n = 10\n",
    "m = 20\n",
    "p = 30\n",
    "tensor1 = torch.rand((batch, n, m))\n",
    "tensor2 = torch.rand((batch, m, p))\n",
    "out_bmm = torch.bmm(tensor1, tensor2)  # Will be shape: (b x n x p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwbFQz3u8jOU"
   },
   "source": [
    "# -- Example of broadcasting --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "2mOt1v0a8mcc"
   },
   "outputs": [],
   "source": [
    "x1 = torch.rand((5, 5))\n",
    "x2 = torch.ones((1, 5))\n",
    "z = (\n",
    "    x1 - x2\n",
    ")  # Shape of z is 5x5: How? The 1x5 vector (x2) is subtracted for each row in the 5x5 (x1)\n",
    "z = (\n",
    "    x1 ** x2\n",
    ")  # Shape of z is 5x5: How? Broadcasting! Element wise exponentiation for every row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jkovRFU8oq0"
   },
   "source": [
    "# Other useful tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "p0tY9ADd8p4l"
   },
   "outputs": [],
   "source": [
    "sum_x = torch.sum(\n",
    "    x, dim=0\n",
    ")  # Sum of x across dim=0 (which is the only dim in our case), sum_x = 6\n",
    "values, indices = torch.max(x, dim=0)  # Can also do x.max(dim=0)\n",
    "values, indices = torch.min(x, dim=0)  # Can also do x.min(dim=0)\n",
    "abs_x = torch.abs(x)  # Returns x where abs function has been applied to every element\n",
    "z = torch.argmax(x, dim=0)  # Gets index of the maximum value\n",
    "z = torch.argmin(x, dim=0)  # Gets index of the minimum value\n",
    "mean_x = torch.mean(x.float(), dim=0)  # mean requires x to be float\n",
    "z = torch.eq(x, y)  # Element wise comparison, in this case z = [False, False, False]\n",
    "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
    "\n",
    "z = torch.clamp(x, min=0)\n",
    "# All values < 0 set to 0 and values > 0 unchanged (this is exactly ReLU function)\n",
    "# If you want to values over max_val to be clamped, do torch.clamp(x, min=min_val, max=max_val)\n",
    "\n",
    "x = torch.tensor([1, 0, 1, 1, 1], dtype=torch.bool)  # True/False values\n",
    "z = torch.any(x)  # will return True, can also do x.any() instead of torch.any(x)\n",
    "z = torch.all(\n",
    "    x\n",
    ")  # will return False (since not all are True), can also do x.all() instead of torch.all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiHPxfuJ8uie"
   },
   "source": [
    "# Tensor Indexing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "DWz73wnm8vqO",
    "outputId": "179491ac-5d8d-4527-8ad9-4fe44dce9b72"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size, features))\n",
    "\n",
    "# Get first examples features\n",
    "print(x[0].shape)  # shape [25], this is same as doing x[0,:]\n",
    "\n",
    "# Get the first feature for all examples\n",
    "print(x[:, 0].shape)  # shape [10]\n",
    "\n",
    "# For example: Want to access third example in the batch and the first ten features\n",
    "print(x[2, 0:10].shape)  # shape: [10]\n",
    "\n",
    "# For example we can use this to, assign certain elements\n",
    "x[0, 0] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuX-1bHF83qm"
   },
   "source": [
    "# Fancy Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "WYeUp-9y84gy",
    "outputId": "1b599dd5-0283-4aa3-d894-a7e6ab4b90ff"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "indices = [2, 5, 8]\n",
    "print(x[indices])  # x[indices] = [2, 5, 8]\n",
    "\n",
    "x = torch.rand((3, 5))\n",
    "rows = torch.tensor([1, 0])\n",
    "cols = torch.tensor([4, 0])\n",
    "print(x[rows, cols])  # Gets second row fifth column and first row first column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9-A_pVR88C_"
   },
   "source": [
    "# More advanced indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1706342899618,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "scPfP-Iw89qw",
    "outputId": "ab9866ce-dfa8-4d3f-c2db-c8739a8123b2"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(10)\n",
    "print(x[(x < 2) | (x > 8)])  # will be [0, 1, 9]\n",
    "print(x[x.remainder(2) == 0])  # will be [0, 2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFgqEy3J8_th"
   },
   "source": [
    "# Useful operations for indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "8RzGxqmD9AhY",
    "outputId": "89e7f8d2-0b96-49b3-bbdc-f71a753497dc"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    torch.where(x > 5, x, x * 2)\n",
    ")  # gives [0, 2, 4, 6, 8, 10, 6, 7, 8, 9], all values x > 5 yield x, else x*2\n",
    "x = torch.tensor([0, 0, 1, 2, 2, 3, 4]).unique()  # x = [0, 1, 2, 3, 4]\n",
    "print(\n",
    "    x.ndimension()\n",
    ")  # The number of dimensions, in this case 1. if x.shape is 5x5x5 ndim would be 3\n",
    "x = torch.arange(10)\n",
    "print(\n",
    "    x.numel()\n",
    ")  # The number of elements in x (in this case it's trivial because it's just a vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjUc9uHp9D8D"
   },
   "source": [
    "# Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "p_nhoh4g9GHZ"
   },
   "outputs": [],
   "source": [
    "x = torch.arange(9)\n",
    "\n",
    "# Let's say we want to reshape it to be 3x3\n",
    "x_3x3 = x.view(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "Mb54c8GQ9Iu0"
   },
   "outputs": [],
   "source": [
    "# We can also do (view and reshape are very similar)\n",
    "# and the differences are in simple terms (I'm no expert at this),\n",
    "# is that view acts on contiguous tensors meaning if the\n",
    "# tensor is stored contiguously in memory or not, whereas\n",
    "# for reshape it doesn't matter because it will copy the\n",
    "# tensor to make it contiguously stored, which might come\n",
    "# with some performance loss.\n",
    "x_3x3 = x.reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "0yum4noA9PjK",
    "outputId": "b413ee11-4d47-4fe9-8ac5-a6ebc375dd08"
   },
   "outputs": [],
   "source": [
    "# If we for example do:\n",
    "y = x_3x3.t()\n",
    "print(\n",
    "    y.is_contiguous()\n",
    ")  # This will return False and if we try to use view now, it won't work!\n",
    "# y.view(9) would cause an error, reshape however won't\n",
    "\n",
    "# This is because in memory it was stored [0, 1, 2, ... 8], whereas now it's [0, 3, 6, 1, 4, 7, 2, 5, 8]\n",
    "# The jump is no longer 1 in memory for one element jump (matrices are stored as a contiguous block, and\n",
    "# using pointers to construct these matrices). This is a bit complicated and I need to explore this more\n",
    "# as well, at least you know it's a problem to be cautious of! A solution is to do the following\n",
    "print(y.contiguous().view(9))  # Calling .contiguous() before view and it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "35AKEIcH9TvH",
    "outputId": "df48535e-646b-4a68-92af-308c9b184de0"
   },
   "outputs": [],
   "source": [
    "# Moving on to another operation, let's say we want to add two tensors dimensions togethor\n",
    "x1 = torch.rand(2, 5)\n",
    "x2 = torch.rand(2, 5)\n",
    "print(torch.cat((x1, x2), dim=0).shape)  # Shape: 4x5\n",
    "print(torch.cat((x1, x2), dim=1).shape)  # Shape 2x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "W7jBSsyY9WEL"
   },
   "outputs": [],
   "source": [
    "# Let's say we want to unroll x1 into one long vector with 10 elements, we can do:\n",
    "z = x1.view(-1)  # And -1 will unroll everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "HAaVaK8c9asA"
   },
   "outputs": [],
   "source": [
    "# If we instead have an additional dimension and we wish to keep those as is we can do:\n",
    "batch = 64\n",
    "x = torch.rand((batch, 2, 5))\n",
    "z = x.view(\n",
    "    batch, -1\n",
    ")  # And z.shape would be 64x10, this is very useful stuff and is used all the time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "YQJA81ZT9cXK"
   },
   "outputs": [],
   "source": [
    "# Let's say we want to switch x axis so that instead of 64x2x5 we have 64x5x2\n",
    "# I.e we want dimension 0 to stay, dimension 1 to become dimension 2, dimension 2 to become dimension 1\n",
    "# Basically you tell permute where you want the new dimensions to be, torch.transpose is a special case\n",
    "# of permute (why?)\n",
    "z = x.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "EWX376Gx9ePt",
    "outputId": "3a1e5e19-7239-4263-fee8-fa2e7b6511f1"
   },
   "outputs": [],
   "source": [
    "# Splits x last dimension into chunks of 2 (since 5 is not integer div by 2) the last dimension\n",
    "# will be smaller, so it will split it into two tensors: 64x2x3 and 64x2x2\n",
    "z = torch.chunk(x, chunks=2, dim=1)\n",
    "print(z[0].shape)\n",
    "print(z[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "X-q8XnGB9fiY",
    "outputId": "a6f84ef2-0cd7-474b-d0f9-15ad23c9a896"
   },
   "outputs": [],
   "source": [
    "# Let's say we want to add an additional dimension\n",
    "x = torch.arange(\n",
    "    10\n",
    ")  # Shape is [10], let's say we want to add an additional so we have 1x10\n",
    "print(x.unsqueeze(0).shape)  # 1x10\n",
    "print(x.unsqueeze(1).shape)  # 10x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "B9Bkbto99hCA"
   },
   "outputs": [],
   "source": [
    "# Let's say we have x which is 1x1x10 and we want to remove a dim so we have 1x10\n",
    "x = torch.arange(10).unsqueeze(0).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1706342899619,
     "user": {
      "displayName": "Pankaj Choudhury",
      "userId": "11381187948817891789"
     },
     "user_tz": -330
    },
    "id": "4BQ1rNZ_9jJC"
   },
   "outputs": [],
   "source": [
    "# Perhaps unsurprisingly\n",
    "z = x.squeeze(1)  # can also do .squeeze(0) both returns 1x10"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMOY7GIU3NqMiW6Jf7drfdc",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
